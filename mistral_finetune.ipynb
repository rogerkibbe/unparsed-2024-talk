{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8002660c8320b8b9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "![BOFH Header](./images/bofh-header.png)\n",
    "# Fine Tuning Mistral 7B to answer tech support questions like the Bastard Operator from Hell\n",
    "## [BOFH on the Web](https://bofh.bjash.com/Support)   |   The Register [BOFH Archive](https://www.theregister.com/offbeat/bofh/)\n",
    "## Support Simon Travaglia the author of BOFH - [Amazon](https://www.amazon.com/stores/Simon-Travaglia/author/B00JCJDZCU)\n",
    "\n",
    "## Sample Q&A Data used for training:\n",
    "### Question: The internet is down\n",
    "### Answer: Oh, the internet is down? Well, stop the presses, alert the media, sound the alarms! It's a global catastrophe! How will you survive without your precious memes and cat videos? Have you tried, I don't know, actually doing some work for a change? No, of course not. That would be too much to ask. Well, let me just put on my Internet Fairy costume and sprinkle some magic pixie dust on the router. But I swear, if I find out you've been hogging all the bandwidth downloading 'Linux ISOs' again, I'm going to throttle your connection so hard, you'll think dial-up is a luxury.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Package install\n",
    "%pip install mistralai pandas pyarrow fastparquet load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb52f294834245",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mistral formatted jsonl file for fine-tuning - See https://docs.mistral.ai/capabilities/finetuning/\n",
    "# Data is Q&A pairs which are IT support questions and answers that the Bastard Operator from Hell (https://bofh.bjash.com/) might say\n",
    "# All data was created with the help of Anthropic's Claude LLM\n",
    "# Data is split into training data and validation data. Mistral's API allows only 5% of data to be validation data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"bofh_training_data_mistral.jsonl\", lines=True)\n",
    "df_train=df.sample(frac=0.96,random_state=200)\n",
    "df_eval=df.drop(df_train.index)\n",
    "\n",
    "df_train.to_json(\"bofh_chunk_train_mistral.jsonl\", orient=\"records\", lines=True)\n",
    "df_eval.to_json(\"bofh_chunk_eval_mistral.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dceefe7300ac5e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample data\n",
    "df.iloc[50]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8cee60da1a019b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get mistral API key from .env file - Get your own key at: https://console.mistral.ai/api-keys/\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from mistralai.client import MistralClient\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ.get(\"MISTRAL_API_KEY\")\n",
    "client = MistralClient(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384428b3a2e638b4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write files to Mistral\n",
    "with open(\"bofh_chunk_train_mistral.jsonl\", \"rb\") as f:\n",
    "    bofh_chunk_train = client.files.create(file=(\"bofh_chunk_train_mistral.jsonl\", f))\n",
    "with open(\"bofh_chunk_eval_mistral.jsonl\", \"rb\") as f:\n",
    "    bofh_chunk_eval = client.files.create(file=(\"bofh_chunk_eval_mistral.jsonl\", f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ba6f64a94881f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pretty print utility function\n",
    "import json\n",
    "def pprint(obj):\n",
    "    print(json.dumps(obj.dict(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4eb8536412f84b2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data about training file stored on Mistral servers\n",
    "pprint(bofh_chunk_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475ea3f21b615441",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data about eval file stored on Mistral servers\n",
    "pprint(bofh_chunk_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682baa762c8ca980",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Do the training\n",
    "from mistralai.models.jobs import TrainingParameters\n",
    "\n",
    "created_jobs = client.jobs.create(\n",
    "    model=\"open-mistral-7b\",\n",
    "    training_files=[bofh_chunk_train.id],\n",
    "    validation_files=[bofh_chunk_eval.id],\n",
    "    hyperparameters=TrainingParameters(\n",
    "        training_steps=10,\n",
    "        learning_rate=0.0001,\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526490ddd76a3fd9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Tuning job data\n",
    "pprint(created_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fbfe430825d0d9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Poll for fine-tuning job status every 10 seconds\n",
    "import time\n",
    "\n",
    "retrieved_job = client.jobs.retrieve(created_jobs.id)\n",
    "while retrieved_job.status in [\"RUNNING\", \"QUEUED\"]:\n",
    "    retrieved_job = client.jobs.retrieve(created_jobs.id)\n",
    "    pprint(retrieved_job)\n",
    "    print(f\"Job is {retrieved_job.status}, waiting 10 seconds\")\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe941afc062a24f3",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List all jobs\n",
    "jobs = client.jobs.list()\n",
    "pprint(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aa4df485d19e15",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve latest job\n",
    "retrieved_jobs = client.jobs.retrieve(created_jobs.id)\n",
    "pprint(retrieved_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85e8787e84b1bc",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The question we will ask the BOFH\n",
    "the_question = \"My mouse is broken\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8548e0ebe63d2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try the fined tuned model\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "chat_response = client.chat(\n",
    "    model=retrieved_jobs.fine_tuned_model,\n",
    "    messages=[ChatMessage(role='user', content=the_question)]\n",
    ")\n",
    "\n",
    "import textwrap\n",
    "\n",
    "print (\"Using model: \" + chat_response.model + \":\")\n",
    "print(textwrap.fill(chat_response.choices[0].message.content, width=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351966eafd1b1047",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try the base Model\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "chat_response = client.chat(\n",
    "    model=\"open-mistral-7b\",\n",
    "    messages=[ChatMessage(role='user', content=the_question)]\n",
    ")\n",
    "print (\"Using model: \" + chat_response.model + \":\")\n",
    "print(textwrap.fill(chat_response.choices[0].message.content, width=80))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
